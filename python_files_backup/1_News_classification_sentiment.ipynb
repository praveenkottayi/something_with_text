{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News classification (Bag of words) and sentiment analysis"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Dataset used # AG's News Topic Classification Dataset\n",
    "# Version 3, Updated 09/09/2015\n",
    "\n",
    "AG is a collection of more than 1 million news articles. News articles have been gathered from more than 2000  \n",
    "news sources by ComeToMyHead in more than 1 year of activity. ComeToMyHead is an academic news search engine \n",
    "which has been running since July, 2004. The dataset is provided by the academic comunity for research purposes\n",
    "in data mining (clustering, classification, etc), information retrieval (ranking, search, etc), xml, data compression,\n",
    "data streaming, and any other non-commercial activity.The AG's news topic classification dataset is constructed by choosing 4 largest classes from the original corpus. Each class contains 30,000 training samples and 1,900 testing samples. The total number of training samples is 120,000 and testing 7,600."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The classes in the dataset are:\n",
    "    1. World\n",
    "    2. Sports\n",
    "    3. Business\n",
    "    4. Sci/Tech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "import csv\n",
    "#import nltk\n",
    "import string\n",
    "import re\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Classifier function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_news_category(x) :\n",
    "    class_output_NB = clf_NB.predict(x)\n",
    "    class_description = \" \"\n",
    "    if class_output_NB == '1':\n",
    "        class_description = \"World\"\n",
    "    if class_output_NB == '2':\n",
    "        class_description = \"Sports\"\n",
    "    if class_output_NB == '3':\n",
    "        class_description = \"Business\"\n",
    "    if class_output_NB == '4':\n",
    "        class_description = \"Sci/Tech\"        \n",
    "    print(\"@NB : This NEWS is related to : \" + class_description)        \n",
    "    class_output_svm = clf_svm.predict(x)\n",
    "    class_description = \" \"\n",
    "    if class_output_svm == '1':\n",
    "        class_description = \"World\"\n",
    "    if class_output_svm == '2':\n",
    "        class_description = \"Sports\"\n",
    "    if class_output_svm == '3':\n",
    "        class_description = \"Business\"\n",
    "    if class_output_svm == '4':\n",
    "        class_description = \"Sci/Tech\"        \n",
    "    print(\"@SVM : This NEWS is related to : \" + class_description)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-7288b0c17e43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# read CSV file & load into list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmy_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mnews_data_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.csv'"
     ]
    }
   ],
   "source": [
    "# read CSV file & load into list\n",
    "with open(\"train.csv\",'r') as my_file:\n",
    "    reader = csv.reader(my_file, delimiter=',')\n",
    "    news_data_train = list(reader)\n",
    "    \n",
    "with open(\"test.csv\",'r') as my_file:\n",
    "    reader = csv.reader(my_file, delimiter=',')\n",
    "    news_data_test = list(reader)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['3', 'Iraq Halts Oil Exports from Main Southern Pipeline (Reuters)', 'Reuters - Authorities have halted oil export\\\\flows from the main pipeline in southern Iraq after\\\\intelligence showed a rebel militia could strike\\\\infrastructure, an oil official said on Saturday.']\n"
     ]
    }
   ],
   "source": [
    "print(news_data_train[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning and combining the text data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords_file = open(\"stopwords.txt\", \"r\" , encoding=\"utf8\") \n",
    "stopwords = stopwords_file.read()\n",
    "#stopwords.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STOPWORD_customized = {'will','new','york','will' ,'quot','year ','company ','week', 'one','two','three','reuters','reuters' , 'monday','tuesday','wednesday','thursday','friday','saturday','sunday','yesterday'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label = [] # class\n",
    "text_doc = [] # news text \n",
    "c =0 # to control count of \n",
    "for i in news_data_train:\n",
    "    c= c+1\n",
    "    if c < 2000:\n",
    "        label.append(i[0])            \n",
    "        merged = i[1]+i[2] # combining header and content \n",
    "        lowers = merged.lower()   # to lower      \n",
    "        no_punctuation = re.sub(r'[^\\w\\s]',' ', lowers)    # remove punctuation\n",
    "        temp = ' '.join(word for word in no_punctuation.split() if len(word)>3) # remove samll words\n",
    "        filtered = ' '.join(word for word in temp.split() if word not in stopwords.split()) # remove stopwords\n",
    "        filtered = ' '.join(word for word in filtered.split() if word not in STOPWORD_customized) # remove stopwords\n",
    "        text_doc.append(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prices soar time record posing menace economy tearaway prices toppling records straining wallets economic menace barely months presidential elections\n"
     ]
    }
   ],
   "source": [
    "print(text_doc[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(text_doc)\n",
    "text = \"\"\n",
    "for i in range (1,len(text_doc)):\n",
    "    temp = (text_doc[i])\n",
    "    text = text + temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "word_count = Counter()\n",
    "word_count.update((word for word in text.split()))\n",
    "#for word, count in word_count.most_common():\n",
    "    #print(word, \":\" ,count,\"\\n\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.getdefaultencoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "#Counter(label).keys() # equals to list(set(words))\n",
    "#Counter(label).values() # counts the elements' frequency\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49999, 69614)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "corpus = text_doc  # processed text corpous \n",
    "X = vectorizer.fit_transform(corpus)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.feature_extraction.text import TfidfTransformer\n",
    "#tf_transformer = TfidfTransformer(use_idf=True).fit(X)\n",
    "#X_tf = tf_transformer.transform(X)\n",
    "#X_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<49999x10000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 761738 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfvectorizer = TfidfVectorizer(max_df=0.5, max_features= 10000, min_df=2, stop_words='english',use_idf= True)\n",
    "X_tfidf = tfvectorizer.fit_transform(corpus)\n",
    "#X_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_tfidf[1].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing dimensionality reduction using LSA\n",
      "done in 255.222253s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Performing dimensionality reduction using LSA\")\n",
    "t0 = time()\n",
    "# Vectorizer results are normalized, which makes KMeans behave as\n",
    "# spherical k-means for better results. Since LSA/SVD results are\n",
    "# not normalized, we have to redo the normalization.\n",
    "svd = TruncatedSVD(1000)\n",
    "normalizer = Normalizer(copy=False)\n",
    "lsa = make_pipeline(svd, normalizer)\n",
    "\n",
    "X_dim_reduced = lsa.fit_transform(X)\n",
    "\n",
    "print(\"done in %fs\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance of the SVD step: 54%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "explained_variance = svd.explained_variance_ratio_.sum()\n",
    "print(\"Explained variance of the SVD step: {}%\".format(\n",
    "int(explained_variance * 100)))\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification (NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X -> full corpus\n",
    "# X_tfidf -> TFIDF reduced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X  has text data as martrix\n",
    "y = label\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf_NB = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "clf = MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_NB.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.94      0.90      0.92     13020\n",
      "          2       0.95      0.99      0.97     12273\n",
      "          3       0.89      0.89      0.89     11947\n",
      "          4       0.91      0.92      0.91     12759\n",
      "\n",
      "avg / total       0.92      0.92      0.92     49999\n",
      "\n",
      "[[11704   503   545   268]\n",
      " [   92 12113    39    29]\n",
      " [  366    71 10638   872]\n",
      " [  339    59   681 11680]]\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "expected = label\n",
    "predicted = clf_NB.predict(X)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_NB.fit(X_tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.92      0.88      0.90     13020\n",
      "          2       0.94      0.98      0.96     12273\n",
      "          3       0.87      0.86      0.87     11947\n",
      "          4       0.89      0.89      0.89     12759\n",
      "\n",
      "avg / total       0.90      0.90      0.90     49999\n",
      "\n",
      "[[11493   577   618   332]\n",
      " [  135 12039    52    47]\n",
      " [  458    98 10302  1089]\n",
      " [  448   116   814 11381]]\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "expected = label\n",
    "predicted = clf_NB.predict(X_tfidf)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification (svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "clf_svm = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      1.00      0.41     13020\n",
      "          2       0.00      0.00      0.00     12273\n",
      "          3       1.00      0.00      0.00     11947\n",
      "          4       0.00      0.00      0.00     12759\n",
      "\n",
      "avg / total       0.31      0.26      0.11     49999\n",
      "\n",
      "[[13020     0     0     0]\n",
      " [12273     0     0     0]\n",
      " [11942     0     5     0]\n",
      " [12759     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "expected = label\n",
    "predicted = clf_svm.predict(X)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm.fit(X_tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#clf.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.26      1.00      0.41     13020\n",
      "          2       0.00      0.00      0.00     12273\n",
      "          3       0.00      0.00      0.00     11947\n",
      "          4       0.00      0.00      0.00     12759\n",
      "\n",
      "avg / total       0.07      0.26      0.11     49999\n",
      "\n",
      "[[13020     0     0     0]\n",
      " [12273     0     0     0]\n",
      " [11947     0     0     0]\n",
      " [12759     0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "expected = label\n",
    "predicted = clf_svm.predict(X_tfidf)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_text = [\" Meanwhile, Idea Cellular on Monday reported a net loss of â‚¹1236 crore for the second quarter of this fiscal due to free voice calls offered by Reliance Jio, disrupting the Indian mobile telephony market. \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tfvectorizer.transform(new_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@NB : This NEWS is related to : Sci/Tech\n",
      "@SVM : This NEWS is related to : World\n"
     ]
    }
   ],
   "source": [
    "find_news_category(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_text = [\" The rise of solar and wind energy has created challenges for GEs power business, which is focused on selling and servicing the turbines and other equipment at the heart of natural gas- and coal-fired plants. GE and Siemens are selling fewer of these systems, raising questions about their ability to capitalize on lucrative service contracts.Our power business is a challenged business right now. Weve got a lot of work to do,said GE CEO John Flannery during a conference call on Monday. \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tfvectorizer.transform(new_text).toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(clf.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@NB : This NEWS is related to : Sci/Tech\n",
      "@SVM : This NEWS is related to : World\n"
     ]
    }
   ],
   "source": [
    "find_news_category(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_text = [\" If Virat plays in his current form for 5 more years, he will break most of the records made by Sachin Tendulkar. \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tfvectorizer.transform(new_text).toarray() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@NB : This NEWS is related to : Sports\n",
      "@SVM : This NEWS is related to : World\n"
     ]
    }
   ],
   "source": [
    "find_news_category(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tweet_sentiment(tweet):\n",
    "    '''\n",
    "    Utility function to classify sentiment of passed tweet\n",
    "    using textblob's sentiment method\n",
    "    '''\n",
    "    # create TextBlob object of passed tweet text\n",
    "    analysis = TextBlob(tweet)\n",
    "    # set sentiment\n",
    "    if analysis.sentiment.polarity >= 0.3:\n",
    "        return 'positive'\n",
    "    elif (analysis.sentiment.polarity < 0):\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tweet_sentiment(new_text[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
